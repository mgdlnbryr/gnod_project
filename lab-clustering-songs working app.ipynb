{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo_ironhack_blue 7](https://user-images.githubusercontent.com/23629340/40541063-a07a0a8a-601a-11e8-91b5-2f13e4e6b441.png)\n",
    "\n",
    "# Lab | Clustering songs\n",
    "\n",
    "##Â Introduction\n",
    "\n",
    "Now it's time to cluster the songs of the **hot_songs** and **not_hot_songs** databases according to the song's audio features. For this purpose, you need to consider the following questions:\n",
    "\n",
    "* Are you going to use all the audio features? If not, which ones do you think that makes more sense to be used?\n",
    "* What is the optimal number of clusters (for methods that need to know this beforehand)?\n",
    "* What is the best distance to use?\n",
    "* What clustering method provides better results?\n",
    "* Does the clustering method need a transformer?\n",
    "\n",
    "## Considerations\n",
    "\n",
    "Be aware that this process is extremely time-consuming!!! (it might take several hours in your laptop). Therefore, when testing different options, save the models into your disk in order to be able to use the best model later. Use pickle for this.  You don't want to retrain the best model again when you know what are the optimal parameters for each.\n",
    "To determine which clustering method performs best, you need to be practical and think how many clusters you might want to have alongside with a [clustering metric](https://analyticsindiamag.com/a-tutorial-on-various-clustering-evaluation-metrics/) to evaluate how good or bad the songs were clustered.\n",
    "If the number of clusters is small, each cluster will be too big and generic. On the other hand, if the number of clusters is too big then each cluster it will be too specific and it will be poorly populated (this it also depend on how heterogeneous is your dataset).\n",
    "\n",
    "On the other hand, when you train your clustering model make sure to concatenate both databases together (ie: **hot_songs** and **not_hot_songs**) before. \n",
    "If you don't combine both datasets, the clusters obtained with the **hot_songs** will be different than the ones obtained with the **not_hot_songs**\n",
    "database even though they might have the same label because they will contain different songs. However, after this you will not know to which original\n",
    "dataframe belongs each song. To prevent this problem, you can add a new column named \"dataset\" with a \"flag\" to remind yourself in which dataset was included\n",
    "each song. \n",
    "\n",
    "Finally, add new column to the full dataset **for each clustering method with the cluster membership of each song** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('extended_songs.csv')\n",
    "\n",
    "# Define the features to be normalized\n",
    "features_to_normalize = ['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'loudness', 'key', 'mode']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "df[features_to_normalize] = scaler.fit_transform(df[features_to_normalize])\n",
    "\n",
    "# Select the features for clustering\n",
    "df_selected = df[features_to_normalize]\n",
    "\n",
    "# Define the range of possible cluster numbers to try\n",
    "cluster_numbers = range(2, 11)  # Start from 2 because silhouette_score requires at least 2 clusters\n",
    "\n",
    "# Initialize an empty list to store the silhouette scores\n",
    "silhouette_scores = []\n",
    "\n",
    "# Perform KMeans for each number of clusters, save the silhouette score\n",
    "for k in cluster_numbers:\n",
    "    model = KMeans(n_clusters=k, random_state=1)\n",
    "    model.fit(df_selected)\n",
    "    score = silhouette_score(df_selected, model.labels_, metric='euclidean')\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot the Silhouette Method graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cluster_numbers, silhouette_scores, 'bo-')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Method For Optimal Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the Silhouette Method graph, choose the optimal number of clusters\n",
    "optimal_clusters = 7 # the number of clusters where the silhouette score is maximum\n",
    "\n",
    "# Apply KMeans clustering with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=1)\n",
    "kmeans.fit(df_selected)\n",
    "\n",
    "# Save the KMeans model\n",
    "pickle.dump(kmeans, open(\"kmeans.pkl\", \"wb\"))\n",
    "\n",
    "# Add the KMeans cluster membership to the dataset\n",
    "df['kmeans_cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=7, random_state=1)\n",
    "kmeans.fit(df_selected)\n",
    "\n",
    "# Save the model\n",
    "pickle.dump(kmeans, open(\"kmeans.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate Silhouette Score\n",
    "score = silhouette_score(df_selected, kmeans.labels_, metric='euclidean')\n",
    "\n",
    "# Print the score\n",
    "print('Silhouette Score: %.3f' % score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster membership to the dataset\n",
    "df['kmeans_cluster'] = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('extended_songs.csv')\n",
    "\n",
    "# Define the features to be normalized\n",
    "features_to_normalize = ['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'loudness', 'key', 'mode']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "df[features_to_normalize] = scaler.fit_transform(df[features_to_normalize])\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "\"\"\"\n",
    "# Select the features for clustering\n",
    "df_selected = df[features_to_normalize]\n",
    "\n",
    "# Apply KMeans clustering with 5 clusters\n",
    "kmeans5 = KMeans(n_clusters=5, random_state=1)\n",
    "kmeans5.fit(df_selected)\n",
    "\n",
    "# Save the KMeans model with 5 clusters\n",
    "pickle.dump(kmeans5, open(\"kmeans5.pkl\", \"wb\"))\n",
    "\n",
    "# Calculate and print the Silhouette Score for 5 clusters\n",
    "score5 = silhouette_score(df_selected, kmeans5.labels_, metric='euclidean')\n",
    "print('Silhouette Score for 5 clusters: %.3f' % score5)\n",
    "\n",
    "# Add the KMeans cluster membership with 5 clusters to the dataset\n",
    "df['kmeans5_cluster'] = kmeans5.labels_\n",
    "\"\"\"\n",
    "\n",
    "# Apply KMeans clustering with 7 clusters\n",
    "kmeans7 = KMeans(n_clusters=7, random_state=1)\n",
    "kmeans7.fit(df_selected)\n",
    "\n",
    "# Save the KMeans model with 7 clusters\n",
    "pickle.dump(kmeans7, open(\"kmeans7.pkl\", \"wb\"))\n",
    "\n",
    "# Calculate and print the Silhouette Score for 7 clusters\n",
    "score7 = silhouette_score(df_selected, kmeans7.labels_, metric='euclidean')\n",
    "print('Silhouette Score for 7 clusters: %.3f' % score7)\n",
    "\n",
    "# Add the KMeans cluster membership with 7 clusters to the dataset\n",
    "df['kmeans7_cluster'] = kmeans7.labels_\n",
    "\n",
    "# save the new dataset as extended_songs_clustered.csv\n",
    "df.to_csv('extended_songs_clustered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('extended_songs_clustered.csv')\n",
    "df.head(1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use the KMeans model to predict the cluster membership of new songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from credentials import *\n",
    "\n",
    "# Load the scaler\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "# Load the KMeans model\n",
    "with open('kmeans7.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Load the song data\n",
    "df = pd.read_csv('extended_songs_clustered.csv')\n",
    "\n",
    "# Create Spotify object\n",
    "credentials = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=credentials)\n",
    "\n",
    "def search_song(title, artist, matches=10):\n",
    "    \"\"\"Search a song on Spotify and return its Spotify ID.\"\"\"\n",
    "    query = f'artist:{artist} track:{title}'\n",
    "    song_ids = []\n",
    "    song_titles = []\n",
    "    song_artists = []\n",
    "    try:\n",
    "        results = sp.search(q=query, type='track', limit=matches)\n",
    "        for i in range(matches):\n",
    "            song_ids.append(results['tracks']['items'][i]['id'])\n",
    "            song_titles.append(results['tracks']['items'][i]['name'])\n",
    "            song_artists.append(results['tracks']['items'][i]['artists'][0]['name'])\n",
    "    except:\n",
    "        print(\"Song not found.\")\n",
    "        \n",
    "    return list(zip(song_ids, song_titles, song_artists))\n",
    "\n",
    "def recommend_songs(song_id):\n",
    "    # Fetch audio features for the selected song\n",
    "    audio_features = sp.audio_features([song_id])[0]\n",
    "    song_df = pd.DataFrame([audio_features])\n",
    "\n",
    "    # Define the features the scaler was trained on\n",
    "    features = ['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'loudness', 'key', 'mode']\n",
    "\n",
    "    # Only keep columns that the scaler was trained on\n",
    "    song_df = song_df[features]\n",
    "\n",
    "    # Scale the audio features and predict the cluster\n",
    "    song_df_scaled = scaler.transform(song_df)\n",
    "\n",
    "    # Convert scaled array back to DataFrame and assign original feature names\n",
    "    song_df_scaled = pd.DataFrame(song_df_scaled, columns=features)\n",
    "\n",
    "    # Predict the cluster\n",
    "    cluster = model.predict(song_df_scaled)[0]\n",
    "\n",
    "    # Check if the song is in our data and is 'hot'\n",
    "    song_in_data = df[(df['id'] == song_id)]\n",
    "    if not song_in_data.empty and song_in_data.iloc[0]['source'] == 'hot':\n",
    "        # If the song is 'hot', recommend other 'hot' songs from the same cluster\n",
    "        recommendations = df[(df['kmeans7_cluster'] == cluster) & (df['source'] == 'hot')]\n",
    "    elif not song_in_data.empty:\n",
    "        # If the song is not 'hot' but in our data, recommend other 'not hot' songs from the same cluster\n",
    "        recommendations = df[(df['kmeans7_cluster'] == cluster) & (df['source'] == 'not_hot')]\n",
    "    else:\n",
    "        # If the song is not in our data, recommend 'not hot' songs from the same cluster\n",
    "        recommendations = df[(df['kmeans7_cluster'] == cluster) & (df['source'] == 'not_hot')]\n",
    "\n",
    "    # Select up to 5 recommendations\n",
    "    recommendations = recommendations.sample(min(5, len(recommendations)))\n",
    "\n",
    "    # Debugging step: Print the columns of the recommendations dataframe\n",
    "    print(f\"Recommendations columns: {recommendations.columns}\")\n",
    "\n",
    "    # Return the recommendations\n",
    "    return (recommendations[['song', 'artist', 'uri']]\n",
    "        .reset_index(drop=True)\n",
    "        .rename(columns={'song': 'Song', 'artist': 'Artist', 'uri': 'URI'})\n",
    "        .rename(lambda x: x + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_songs('3KkXRkHbMCARz0aVfEt68P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations columns: Index(['song', 'artist', 'source', 'id', 'danceability', 'energy', 'key',\n",
      "       'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
      "       'liveness', 'valence', 'tempo', 'type', 'id.1', 'uri', 'track_href',\n",
      "       'analysis_url', 'duration_ms', 'time_signature', 'kmeans7_cluster'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QPushButton, QLineEdit, QLabel, QInputDialog, QListWidget, QListWidgetItem, QDialog\n",
    "from PyQt5.QtCore import Qt, QUrl\n",
    "from PyQt5.QtGui import QDesktopServices, QFont\n",
    "import webbrowser\n",
    "\n",
    "class SongRecommenderApp(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.title = 'SongGPT'\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle(self.title)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.label_header = QLabel('SoundGPT - Make Your Sound Come True')\n",
    "        self.label_header.setFont(QFont('Arial', 20, QFont.Bold))\n",
    "\n",
    "        self.label_song = QLabel('Enter a song title:')\n",
    "        self.line_edit_song = QLineEdit()\n",
    "\n",
    "        self.label_artist = QLabel('Enter the song artist:')\n",
    "        self.line_edit_artist = QLineEdit()\n",
    "\n",
    "        self.button = QPushButton('Search Songs')\n",
    "        self.button.clicked.connect(self.on_click)\n",
    "\n",
    "        layout.addWidget(self.label_header)\n",
    "        layout.addWidget(self.label_song)\n",
    "        layout.addWidget(self.line_edit_song)\n",
    "        layout.addWidget(self.label_artist)\n",
    "        layout.addWidget(self.line_edit_artist)\n",
    "        layout.addWidget(self.button)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def on_click(self):\n",
    "        song = self.line_edit_song.text()\n",
    "        artist = self.line_edit_artist.text()\n",
    "\n",
    "        # Get song suggestions\n",
    "        suggestions = search_song(song, artist)\n",
    "\n",
    "        # Create a new dialog to display the suggestions\n",
    "        dialog = SongSelectionDialog(suggestions)\n",
    "\n",
    "        # If the user confirmed the selection, get the selected song and artist\n",
    "        if dialog.exec_():\n",
    "            song_id, song, artist = dialog.selected_song\n",
    "\n",
    "            # Fetch audio features, scale the features, predict the cluster, and get song recommendations\n",
    "            recommendations = recommend_songs(song_id)\n",
    "\n",
    "            # Create a new dialog to display the song recommendations\n",
    "            dialog = SongRecommendationsDialog(recommendations)\n",
    "            dialog.exec_()\n",
    "\n",
    "\n",
    "class SongSelectionDialog(QDialog):\n",
    "    def __init__(self, suggestions):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle('Select a Song')\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.list_widget = QListWidget()\n",
    "\n",
    "        for song_id, song, artist in suggestions:\n",
    "            item = QListWidgetItem(f'{song} by {artist}')\n",
    "            item.setData(Qt.UserRole, (song_id, song, artist))  # Store song_id, song, and artist in the item data\n",
    "            self.list_widget.addItem(item)\n",
    "\n",
    "        self.list_widget.itemDoubleClicked.connect(self.accept)  # Accept the dialog when an item is double clicked\n",
    "\n",
    "        layout.addWidget(self.list_widget)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    @property\n",
    "    def selected_song(self):\n",
    "        item = self.list_widget.currentItem()\n",
    "        return item.data(Qt.UserRole)  # Return song_id, song, and artist of the selected item\n",
    "\n",
    "\n",
    "class SongRecommendationsDialog(QDialog):\n",
    "    def __init__(self, recommendations):\n",
    "        super().__init__()\n",
    "\n",
    "        self.setWindowTitle('Song Recommendations')\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.list_widget = QListWidget()\n",
    "        self.list_widget.itemDoubleClicked.connect(self.on_item_double_clicked)\n",
    "\n",
    "        for row in recommendations.itertuples():\n",
    "            song = row.Song\n",
    "            artist = row.Artist\n",
    "            uri = row.URI\n",
    "            item = QListWidgetItem(f'{song} by {artist}')\n",
    "            item.setData(Qt.UserRole, uri)  # Store uri in the item data\n",
    "            self.list_widget.addItem(item)\n",
    "\n",
    "        self.repeat_button = QPushButton('Repeat')\n",
    "        self.repeat_button.clicked.connect(self.close)\n",
    "\n",
    "        self.exit_button = QPushButton('Exit')\n",
    "        self.exit_button.clicked.connect(QApplication.instance().quit)\n",
    "\n",
    "        layout.addWidget(self.list_widget)\n",
    "        layout.addWidget(self.repeat_button)\n",
    "        layout.addWidget(self.exit_button)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def on_item_double_clicked(self, item):\n",
    "        uri = item.data(Qt.UserRole)\n",
    "        webbrowser.open(uri)\n",
    "\n",
    "\n",
    "def main():\n",
    "    app = QApplication([])\n",
    "    app.setStyleSheet(\"QWidget { background-color: black; color: lightgreen }\")\n",
    "\n",
    "    window = SongRecommenderApp()\n",
    "    window.show()\n",
    "\n",
    "    app.exec_()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
